{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Yolov3_evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbionKransiqi/Capstone/blob/main/Yolov3_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anDPyuwmsrTW"
      },
      "source": [
        "**Loading the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmNaNoOSpdoj"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "import skimage.io\n",
        "from glob import glob\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J1zvq-ApANA",
        "outputId": "cbcf9216-07f3-4a4a-a14c-fe1e99df27e3"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z_MXJNKsjHw"
      },
      "source": [
        "**Measuring the performance of the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wxqo_ni3bgup",
        "scrolled": false,
        "outputId": "eba78411-3162-4523-99e0-a3742bcac2fa"
      },
      "source": [
        "# ## loading the trained model and running mAP evaluation\n",
        "!./darknet detector map data/frieburg.data yolov3_custom_train.cfg yolov3_custom_train_6000.weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "net.optimized_memory = 0 \n",
            "mini_batch = 1, batch = 16, time_steps = 1, train = 0 \n",
            "\n",
            " seen 64, trained: 384 K-images (6 Kilo-batches_64) \n",
            "\n",
            " calculation mAP (mean average precision)...\n",
            " Detection layer: 82 - type = 28 \n",
            " Detection layer: 94 - type = 28 \n",
            " Detection layer: 106 - type = 28 \n",
            "\n",
            " detections_count = 5351, unique_truth_count = 2261  \n",
            " rank = 0 of ranks = 5351 \r",
            " rank = 100 of ranks = 5351 \r",
            " rank = 200 of ranks = 5351 \r",
            " rank = 300 of ranks = 5351 \r",
            " rank = 400 of ranks = 5351 \r",
            " rank = 500 of ranks = 5351 \r",
            " rank = 600 of ranks = 5351 \r",
            " rank = 700 of ranks = 5351 \r",
            " rank = 800 of ranks = 5351 \r",
            " rank = 900 of ranks = 5351 \r",
            " rank = 1000 of ranks = 5351 \r",
            " rank = 1100 of ranks = 5351 \r",
            " rank = 1200 of ranks = 5351 \r",
            " rank = 1300 of ranks = 5351 \r",
            " rank = 1400 of ranks = 5351 \r",
            " rank = 1500 of ranks = 5351 \r",
            " rank = 1600 of ranks = 5351 \r",
            " rank = 1700 of ranks = 5351 \r",
            " rank = 1800 of ranks = 5351 \r",
            " rank = 1900 of ranks = 5351 \r",
            " rank = 2000 of ranks = 5351 \r",
            " rank = 2100 of ranks = 5351 \r",
            " rank = 2200 of ranks = 5351 \r",
            " rank = 2300 of ranks = 5351 \r",
            " rank = 2400 of ranks = 5351 \r",
            " rank = 2500 of ranks = 5351 \r",
            " rank = 2600 of ranks = 5351 \r",
            " rank = 2700 of ranks = 5351 \r",
            " rank = 2800 of ranks = 5351 \r",
            " rank = 2900 of ranks = 5351 \r",
            " rank = 3000 of ranks = 5351 \r",
            " rank = 3100 of ranks = 5351 \r",
            " rank = 3200 of ranks = 5351 \r",
            " rank = 3300 of ranks = 5351 \r",
            " rank = 3400 of ranks = 5351 \r",
            " rank = 3500 of ranks = 5351 \r",
            " rank = 3600 of ranks = 5351 \r",
            " rank = 3700 of ranks = 5351 \r",
            " rank = 3800 of ranks = 5351 \r",
            " rank = 3900 of ranks = 5351 \r",
            " rank = 4000 of ranks = 5351 \r",
            " rank = 4100 of ranks = 5351 \r",
            " rank = 4200 of ranks = 5351 \r",
            " rank = 4300 of ranks = 5351 \r",
            " rank = 4400 of ranks = 5351 \r",
            " rank = 4500 of ranks = 5351 \r",
            " rank = 4600 of ranks = 5351 \r",
            " rank = 4700 of ranks = 5351 \r",
            " rank = 4800 of ranks = 5351 \r",
            " rank = 4900 of ranks = 5351 \r",
            " rank = 5000 of ranks = 5351 \r",
            " rank = 5100 of ranks = 5351 \r",
            " rank = 5200 of ranks = 5351 \r",
            " rank = 5300 of ranks = 5351 \r",
            "class_id = 0, name = beans, ap = 84.26%   \t (TP = 33, FP = 9) \n",
            "class_id = 1, name = cake, ap = 84.02%   \t (TP = 31, FP = 6) \n",
            "class_id = 2, name = candy, ap = 75.92%   \t (TP = 74, FP = 8) \n",
            "class_id = 3, name = cereal, ap = 90.44%   \t (TP = 67, FP = 12) \n",
            "class_id = 4, name = chips, ap = 79.68%   \t (TP = 66, FP = 13) \n",
            "class_id = 5, name = chocolate, ap = 66.65%   \t (TP = 70, FP = 19) \n",
            "class_id = 6, name = coffee, ap = 85.83%   \t (TP = 121, FP = 20) \n",
            "class_id = 7, name = corn, ap = 88.03%   \t (TP = 46, FP = 11) \n",
            "class_id = 8, name = fish, ap = 83.29%   \t (TP = 51, FP = 15) \n",
            "class_id = 9, name = flour, ap = 85.85%   \t (TP = 35, FP = 9) \n",
            "class_id = 10, name = honey, ap = 92.90%   \t (TP = 50, FP = 12) \n",
            "class_id = 11, name = jam, ap = 96.21%   \t (TP = 146, FP = 16) \n",
            "class_id = 12, name = juice, ap = 91.50%   \t (TP = 138, FP = 41) \n",
            "class_id = 13, name = milk, ap = 92.38%   \t (TP = 66, FP = 15) \n",
            "class_id = 14, name = nuts, ap = 76.07%   \t (TP = 45, FP = 9) \n",
            "class_id = 15, name = oil, ap = 82.55%   \t (TP = 57, FP = 26) \n",
            "class_id = 16, name = pasta, ap = 73.13%   \t (TP = 48, FP = 15) \n",
            "class_id = 17, name = rice, ap = 83.45%   \t (TP = 33, FP = 8) \n",
            "class_id = 18, name = soda, ap = 77.88%   \t (TP = 94, FP = 18) \n",
            "class_id = 19, name = spices, ap = 92.62%   \t (TP = 94, FP = 17) \n",
            "class_id = 20, name = sugar, ap = 78.12%   \t (TP = 48, FP = 12) \n",
            "class_id = 21, name = tea, ap = 88.13%   \t (TP = 116, FP = 30) \n",
            "class_id = 22, name = tomato_sauce, ap = 84.88%   \t (TP = 53, FP = 9) \n",
            "class_id = 23, name = vinegar, ap = 87.42%   \t (TP = 77, FP = 9) \n",
            "class_id = 24, name = water, ap = 93.55%   \t (TP = 133, FP = 22) \n",
            "\n",
            " for conf_thresh = 0.25, precision = 0.82, recall = 0.79, F1-score = 0.81 \n",
            " for conf_thresh = 0.25, TP = 1792, FP = 381, FN = 469, average IoU = 70.10 % \n",
            "\n",
            " IoU threshold = 50 %, used Area-Under-Curve for each unique Recall \n",
            " mean average precision (mAP@0.50) = 0.845915, or 84.59 % \n",
            "\n",
            "Set -points flag:\n",
            " `-points 101` for MS COCO \n",
            " `-points 11` for PascalVOC 2007 (uncomment `difficult` in voc.data) \n",
            " `-points 0` (AUC) for ImageNet, PascalVOC 2010-2012, your custom dataset\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " CUDA-version: 10010 (10010), cuDNN: 7.6.5, GPU count: 1  \n",
            " OpenCV version: 3.2.0\n",
            " 0 : compute_capability = 750, cudnn_half = 0, GPU: Tesla T4 \n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv     32       3 x 3/ 1    416 x 416 x   3 ->  416 x 416 x  32 0.299 BF\n",
            "   1 conv     64       3 x 3/ 2    416 x 416 x  32 ->  208 x 208 x  64 1.595 BF\n",
            "   2 conv     32       1 x 1/ 1    208 x 208 x  64 ->  208 x 208 x  32 0.177 BF\n",
            "   3 conv     64       3 x 3/ 1    208 x 208 x  32 ->  208 x 208 x  64 1.595 BF\n",
            "   4 Shortcut Layer: 1,  wt = 0, wn = 0, outputs: 208 x 208 x  64 0.003 BF\n",
            "   5 conv    128       3 x 3/ 2    208 x 208 x  64 ->  104 x 104 x 128 1.595 BF\n",
            "   6 conv     64       1 x 1/ 1    104 x 104 x 128 ->  104 x 104 x  64 0.177 BF\n",
            "   7 conv    128       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x 128 1.595 BF\n",
            "   8 Shortcut Layer: 5,  wt = 0, wn = 0, outputs: 104 x 104 x 128 0.001 BF\n",
            "   9 conv     64       1 x 1/ 1    104 x 104 x 128 ->  104 x 104 x  64 0.177 BF\n",
            "  10 conv    128       3 x 3/ 1    104 x 104 x  64 ->  104 x 104 x 128 1.595 BF\n",
            "  11 Shortcut Layer: 8,  wt = 0, wn = 0, outputs: 104 x 104 x 128 0.001 BF\n",
            "  12 conv    256       3 x 3/ 2    104 x 104 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  13 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  14 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  15 Shortcut Layer: 12,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  16 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  17 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  18 Shortcut Layer: 15,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  19 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  20 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  21 Shortcut Layer: 18,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  22 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  23 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  24 Shortcut Layer: 21,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  25 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  26 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  27 Shortcut Layer: 24,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  28 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  29 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  30 Shortcut Layer: 27,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  31 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  32 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  33 Shortcut Layer: 30,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  34 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            "  35 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            "  36 Shortcut Layer: 33,  wt = 0, wn = 0, outputs:  52 x  52 x 256 0.001 BF\n",
            "  37 conv    512       3 x 3/ 2     52 x  52 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  38 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  39 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  40 Shortcut Layer: 37,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  41 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  42 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  43 Shortcut Layer: 40,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  44 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  45 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  46 Shortcut Layer: 43,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  47 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  48 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  49 Shortcut Layer: 46,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  50 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  51 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  52 Shortcut Layer: 49,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  53 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  54 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  55 Shortcut Layer: 52,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  56 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  57 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  58 Shortcut Layer: 55,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  59 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  60 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  61 Shortcut Layer: 58,  wt = 0, wn = 0, outputs:  26 x  26 x 512 0.000 BF\n",
            "  62 conv   1024       3 x 3/ 2     26 x  26 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  63 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  64 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  65 Shortcut Layer: 62,  wt = 0, wn = 0, outputs:  13 x  13 x1024 0.000 BF\n",
            "  66 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  67 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  68 Shortcut Layer: 65,  wt = 0, wn = 0, outputs:  13 x  13 x1024 0.000 BF\n",
            "  69 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  70 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  71 Shortcut Layer: 68,  wt = 0, wn = 0, outputs:  13 x  13 x1024 0.000 BF\n",
            "  72 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  73 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  74 Shortcut Layer: 71,  wt = 0, wn = 0, outputs:  13 x  13 x1024 0.000 BF\n",
            "  75 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  76 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  77 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  78 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  79 conv    512       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 512 0.177 BF\n",
            "  80 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
            "  81 conv     90       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x  90 0.031 BF\n",
            "  82 yolo\n",
            "[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "  83 route  79 \t\t                           ->   13 x  13 x 512 \n",
            "  84 conv    256       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x 256 0.044 BF\n",
            "  85 upsample                 2x    13 x  13 x 256 ->   26 x  26 x 256\n",
            "  86 route  85 61 \t                           ->   26 x  26 x 768 \n",
            "  87 conv    256       1 x 1/ 1     26 x  26 x 768 ->   26 x  26 x 256 0.266 BF\n",
            "  88 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  89 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  90 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  91 conv    256       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x 256 0.177 BF\n",
            "  92 conv    512       3 x 3/ 1     26 x  26 x 256 ->   26 x  26 x 512 1.595 BF\n",
            "  93 conv     90       1 x 1/ 1     26 x  26 x 512 ->   26 x  26 x  90 0.062 BF\n",
            "  94 yolo\n",
            "[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "  95 route  91 \t\t                           ->   26 x  26 x 256 \n",
            "  96 conv    128       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x 128 0.044 BF\n",
            "  97 upsample                 2x    26 x  26 x 128 ->   52 x  52 x 128\n",
            "  98 route  97 36 \t                           ->   52 x  52 x 384 \n",
            "  99 conv    128       1 x 1/ 1     52 x  52 x 384 ->   52 x  52 x 128 0.266 BF\n",
            " 100 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 101 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            " 102 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 103 conv    128       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x 128 0.177 BF\n",
            " 104 conv    256       3 x 3/ 1     52 x  52 x 128 ->   52 x  52 x 256 1.595 BF\n",
            " 105 conv     90       1 x 1/ 1     52 x  52 x 256 ->   52 x  52 x  90 0.125 BF\n",
            " 106 yolo\n",
            "[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 65.479 \n",
            "avg_outputs = 521499 \n",
            " Allocate additional workspace_size = 52.43 MB \n",
            "Loading weights from yolov3_custom_train_6000.weights...Done! Loaded 107 layers from weights-file \n",
            "\r",
            "4\r",
            "8\r",
            "12\r",
            "16\r",
            "20\r",
            "24\r",
            "28\r",
            "32\r",
            "36\r",
            "40\r",
            "44\r",
            "48\r",
            "52\r",
            "56\r",
            "60\r",
            "64\r",
            "68\r",
            "72\r",
            "76\r",
            "80\r",
            "84\r",
            "88\r",
            "92\r",
            "96\r",
            "100\r",
            "104\r",
            "108\r",
            "112\r",
            "116\r",
            "120\r",
            "124\r",
            "128\r",
            "132\r",
            "136\r",
            "140\r",
            "144\r",
            "148\r",
            "152\r",
            "156\r",
            "160\r",
            "164\r",
            "168\r",
            "172\r",
            "176\r",
            "180\r",
            "184\r",
            "188\r",
            "192\r",
            "196\r",
            "200\r",
            "204\r",
            "208\r",
            "212\r",
            "216\r",
            "220\r",
            "224\r",
            "228\r",
            "232\r",
            "236\r",
            "240\r",
            "244\r",
            "248\r",
            "252\r",
            "256\r",
            "260\r",
            "264\r",
            "268\r",
            "272\r",
            "276\r",
            "280\r",
            "284\r",
            "288\r",
            "292\r",
            "296\r",
            "300\r",
            "304\r",
            "308\r",
            "312\r",
            "316\r",
            "320\r",
            "324\r",
            "328\r",
            "332\r",
            "336\r",
            "340\r",
            "344\r",
            "348\r",
            "352\r",
            "356\r",
            "360\r",
            "364\r",
            "368\r",
            "372\r",
            "376\r",
            "380\r",
            "384\r",
            "388\r",
            "392\r",
            "396\r",
            "400\r",
            "404\r",
            "408\r",
            "412\r",
            "416\r",
            "420\r",
            "424\r",
            "428\r",
            "432\r",
            "436\r",
            "440\r",
            "444\r",
            "448\r",
            "452\r",
            "456\r",
            "460\r",
            "464\r",
            "468\r",
            "472\r",
            "476\r",
            "480\r",
            "484\r",
            "488\r",
            "492\r",
            "496\r",
            "500\r",
            "504\r",
            "508\r",
            "512\r",
            "516\r",
            "520\r",
            "524\r",
            "528\r",
            "532\r",
            "536\r",
            "540\r",
            "544\r",
            "548\r",
            "552\r",
            "556\r",
            "560\r",
            "564\r",
            "568\r",
            "572\r",
            "576\r",
            "580\r",
            "584\r",
            "588\r",
            "592\r",
            "596\r",
            "600\r",
            "604\r",
            "608\r",
            "612\r",
            "616\r",
            "620\r",
            "624\r",
            "628\r",
            "632\r",
            "636\r",
            "640\r",
            "644\r",
            "648\r",
            "652\r",
            "656\r",
            "660\r",
            "664\r",
            "668\r",
            "672\r",
            "676\r",
            "680\r",
            "684\r",
            "688\r",
            "692\r",
            "696\r",
            "700\r",
            "704\r",
            "708\r",
            "712\r",
            "716\r",
            "720\r",
            "724\r",
            "728\r",
            "732\r",
            "736\r",
            "740\r",
            "744\r",
            "748\r",
            "752\r",
            "756\r",
            "760\r",
            "764\r",
            "768\r",
            "772\r",
            "776\r",
            "780\r",
            "784\r",
            "788\r",
            "792\r",
            "796\r",
            "800\r",
            "804\r",
            "808\r",
            "812\r",
            "816\r",
            "820\r",
            "824\r",
            "828\r",
            "832\r",
            "836\r",
            "840\r",
            "844\r",
            "848\r",
            "852\r",
            "856\r",
            "860\r",
            "864\r",
            "868\r",
            "872\r",
            "876\r",
            "880\r",
            "884\r",
            "888\r",
            "892\r",
            "896\r",
            "900\r",
            "904\r",
            "908\r",
            "912\r",
            "916\r",
            "920\r",
            "924\r",
            "928\r",
            "932\r",
            "936\r",
            "940\r",
            "944\r",
            "948\r",
            "952\r",
            "956\r",
            "960\r",
            "964\r",
            "968\r",
            "972\r",
            "976\r",
            "980\r",
            "984\r",
            "988Total Detection Time: 23 Seconds\n"
          ]
        }
      ]
    }
  ]
}